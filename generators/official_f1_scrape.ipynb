{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data generator from formula1.com\n",
        "\n",
        "With this script you can push new results posted in the formula 1 official page to the database. This script will be run as soon as possible after each race, so don't worry about reporting this. It is much more important to complete the data that does not come automatically from scraping!\n",
        "\n",
        "The results will be saved in csv files. You have to specify the season and the round of the event that you want to scrape. Results of the race, qualy, practices will be generated.\n",
        "\n",
        "Subsequent manual analysis is required, since this scraped data can carry errors (for example, Nelson Piquet in the 2008/2009 season is assigned the identifier of his father, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 547,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from urllib import request\n",
        "import os\n",
        "from unidecode import unidecode\n",
        "import bs4 as bs\n",
        "from typing import Literal\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 548,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path of the current data\n",
        "INPUT_PATH = \"./../data/csv/\"\n",
        "\n",
        "# Path to generate the new db files\n",
        "OUTPUT_PATH = \"generated/Data to append to the DB\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_PATH):\n",
        "   os.makedirs(OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 549,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_df(df: DataFrame | None, name: str):\n",
        "    if df is not None:\n",
        "        df.to_csv(f\"{OUTPUT_PATH}/{name}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 550,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loc_existing_columns(df: DataFrame, columns: list[str]):\n",
        "    \"\"\"Receives a dataframe an a list of columns, and returns the dataframe only with the\n",
        "    columns of the list\n",
        "    \"\"\"\n",
        "\n",
        "    invalid_cols = [column for column in columns if column not in df.columns]\n",
        "\n",
        "    for col in invalid_cols:\n",
        "        df[col] = \"\"\n",
        "\n",
        "    valid_cols = [column for column in columns if column in df.columns]\n",
        "\n",
        "    return df.loc[:, valid_cols]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 551,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_milliseconds(text: str):\n",
        "    \"\"\"Receives a string in the format `HH:mm:ss.SSS` and return the converted milliseconds\"\"\"\n",
        "\n",
        "    if not isinstance(text, str) and not np.isnan(float(text)):\n",
        "        return round(float(text) * 1000)\n",
        "\n",
        "    try:\n",
        "        splitted = list(map(float, text.split(\":\")))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    result = splitted[-1]\n",
        "    if len(splitted) >= 2:\n",
        "        result += splitted[-2] * 60\n",
        "    if len(splitted) >= 3:\n",
        "        result += splitted[-3] * 3600\n",
        "\n",
        "    return round(result * 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 552,
      "metadata": {},
      "outputs": [],
      "source": [
        "drivers_in_db = pd.read_csv(INPUT_PATH + \"drivers.csv\")\n",
        "\n",
        "\n",
        "def find_driverId(driver_name: str):\n",
        "    driver_name = unidecode(driver_name).replace(\"-\", \" \").lower()\n",
        "\n",
        "    for index, row in drivers_in_db.iterrows():\n",
        "        if driver_name == unidecode(row[\"name\"]).replace(\"-\", \" \").lower():\n",
        "            return str(row[\"id\"])\n",
        "\n",
        "    for index, row in drivers_in_db.iterrows():\n",
        "        if driver_name == unidecode(row[\"fullName\"]).replace(\"-\", \" \").lower():\n",
        "            return str(row[\"id\"])\n",
        "\n",
        "    for index, row in drivers_in_db.iterrows():\n",
        "        if (\n",
        "            driver_name.split(\" \")[-1]\n",
        "            in unidecode(row[\"fullName\"]).replace(\"-\", \" \").lower()\n",
        "        ):\n",
        "            return str(row[\"id\"])\n",
        "\n",
        "    return \"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 553,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_race_urls(season:int):\n",
        "    year = str(season)\n",
        "    race_urls: list[str] = []\n",
        "    source = request.urlopen(\n",
        "        f\"https://www.formula1.com/en/results.html/{year}/races.html\"\n",
        "    ).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    for url in soup.find_all(\"a\"):\n",
        "        if (\n",
        "            year in str(url.get(\"href\"))\n",
        "            and \"race-result\" in str(url.get(\"href\"))\n",
        "            and url.get(\"href\") not in race_urls\n",
        "        ):\n",
        "            race_urls.append(url.get(\"href\"))\n",
        "    \n",
        "    return race_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 554,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_race_data(\n",
        "    race_url: str,\n",
        "    data_to_get: Literal[\n",
        "        \"pit_stops\", \"qualifying\", \"fp1\", \"fp2\", \"fp3\", \"fp4\", \"wu\", \"race_results\"\n",
        "    ],\n",
        "    season: int,\n",
        "    round: int,\n",
        "):\n",
        "    last_path_slot: str\n",
        "\n",
        "    if data_to_get == \"pit_stops\":\n",
        "        last_path_slot = \"/pit-stop-summary.html\"\n",
        "    elif data_to_get == \"qualifying\":\n",
        "        last_path_slot = \"/qualifying-0.html\"\n",
        "    elif data_to_get == \"fp1\":\n",
        "        last_path_slot = \"/practice-1.html\"\n",
        "    elif data_to_get == \"fp2\":\n",
        "        last_path_slot = \"/practice-2.html\"\n",
        "    elif data_to_get == \"fp3\":\n",
        "        last_path_slot = \"/practice-3.html\"\n",
        "    elif data_to_get == \"fp4\":\n",
        "        last_path_slot = \"/practice-4.html\"\n",
        "    elif data_to_get == \"wu\":\n",
        "        last_path_slot = \"/practice-0.html\"\n",
        "    elif data_to_get == \"race_results\":\n",
        "        last_path_slot = \"/race-result.html\"\n",
        "\n",
        "    source = request.urlopen(\n",
        "        \"https://www.formula1.com/\"\n",
        "        + \"/\".join(race_url.split(\"/\")[:-1])\n",
        "        + last_path_slot\n",
        "    ).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    SIDENAV_LIST = soup.find(\"ul\", {\"class\": \"resultsarchive-side-nav\"})\n",
        "\n",
        "    if not SIDENAV_LIST:\n",
        "        return None\n",
        "\n",
        "    if data_to_get == \"pit_stops\" and not \"Pit stop summary\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "\n",
        "    if data_to_get == \"wu\" and not \"Warm Up\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "    \n",
        "    if data_to_get == \"race_result\" and not \"Race result\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        if data_to_get == f\"fp{i}\" and not f\"Practice {i}\" in SIDENAV_LIST.text:\n",
        "            return None\n",
        "\n",
        "    table = soup.find_all(\"table\")[0]\n",
        "    df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
        "\n",
        "    # Get driver ID\n",
        "    df[\"Driver\"] = df[\"Driver\"].apply(lambda x: \" \".join(x.split(\" \")[:-1]))\n",
        "    df[\"driverId\"] = df[\"Driver\"].map(find_driverId)\n",
        "\n",
        "    # Remove unnamed columns\n",
        "    df = df.loc[:, ~df.columns.str.startswith(\"Unnamed: \")]\n",
        "\n",
        "    df[\"season\"] = season\n",
        "    df[\"round\"] = round\n",
        "\n",
        "    df[\"eventId\"] = f\"{season}-{round}\"\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 555,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Race to get -> Season + Round\n",
        "SEASON = 2002\n",
        "ROUND = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 556,
      "metadata": {},
      "outputs": [],
      "source": [
        "races_url = get_race_urls(SEASON)\n",
        "race = races_url[ROUND - 1]\n",
        "\n",
        "# Comment any of the following blocks to speed-up the proccess:\n",
        "qualifying_df = get_race_data(race, \"qualifying\", SEASON, ROUND)\n",
        "pit_stop_df = get_race_data(race, \"pit_stops\", SEASON, ROUND)\n",
        "fp1_df = get_race_data(race, \"fp1\", SEASON, ROUND)\n",
        "fp2_df = get_race_data(race, \"fp2\", SEASON, ROUND)\n",
        "fp3_df = get_race_data(race, \"fp3\", SEASON, ROUND)\n",
        "fp4_df = get_race_data(race, \"fp4\", SEASON, ROUND)\n",
        "wu_df = get_race_data(race, \"wu\", SEASON, ROUND)\n",
        "race_df = get_race_data(race, \"race_results\", SEASON, ROUND)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 557,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check that all drivers has been found in our DB\n",
        "for df in [qualifying_df, pit_stop_df, fp1_df, fp2_df, fp3_df]:\n",
        "    if df is not None:\n",
        "        DRIVERS_WITHOUT_ID = df[df[\"driverId\"] == \"\"]\n",
        "        if len(DRIVERS_WITHOUT_ID) > 0:\n",
        "            raise Exception(\n",
        "                \"Can not find any id for this drivers: \",\n",
        "                DRIVERS_WITHOUT_ID[\"Driver\"].unique(),\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 558,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "--------------- RACE RESULTS --------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if race_df is not None:\n",
        "    race_df[\"positionOrder\"] = race_df.index + 1\n",
        "\n",
        "    race_df = loc_existing_columns(\n",
        "        race_df,\n",
        "        [\n",
        "            \"eventId\",\n",
        "            \"driverId\",\n",
        "            \"Pos\",\n",
        "            \"positionOrder\",\n",
        "            \"time\",\n",
        "            \"gridPos\",\n",
        "            \"Time/Retired\",\n",
        "            \"Laps\",\n",
        "            \"PTS\",\n",
        "            \"gap\",\n",
        "            \"timePenalty\",\n",
        "            \"reasonRetired\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    race_df.rename(\n",
        "        columns={\"Laps\": \"laps\", \"PTS\": \"points\", \"Pos\": \"positionText\"}, inplace=True\n",
        "    )\n",
        "\n",
        "    race_df[\"gridPos\"] = \"COMPLETE_ME\"\n",
        "\n",
        "    race_df[\"gap\"] = race_df.apply(\n",
        "        lambda x: x[\"Time/Retired\"]\n",
        "        if x[\"Time/Retired\"] != \"DNF\" and x[\"positionOrder\"] != 1\n",
        "        else \"\",\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    race_df.at[0, \"time\"] = convert_to_milliseconds(race_df.at[0, \"Time/Retired\"])\n",
        "\n",
        "    race_df[\"time\"] = race_df.apply(\n",
        "        lambda x: race_df.at[0, \"time\"]\n",
        "        + convert_to_milliseconds(\n",
        "            str(x[\"Time/Retired\"]).replace(\"+\", \"\").replace(\"s\", \"\")\n",
        "        )\n",
        "        if \"lap\" not in x[\"Time/Retired\"]\n",
        "        and x[\"positionOrder\"] != 1\n",
        "        and convert_to_milliseconds(\n",
        "            str(x[\"Time/Retired\"]).replace(\"+\", \"\").replace(\"s\", \"\")\n",
        "        )\n",
        "        is not None\n",
        "        else \"\",\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    race_df.at[0, \"time\"] = convert_to_milliseconds(race_df.at[0, \"Time/Retired\"])\n",
        "\n",
        "    race_df[\"positionText\"] = race_df.apply(\n",
        "        lambda x: \"DNF\" if x[\"positionText\"] == \"NC\" else x[\"positionText\"], axis=1\n",
        "    )\n",
        "\n",
        "    race_df[\"reasonRetired\"] = race_df.apply(\n",
        "        lambda x: \"COMPLETE_ME\" if x[\"positionText\"] == \"DNF\" else \"\", axis=1\n",
        "    )\n",
        "\n",
        "    race_df.drop(columns=[\"Time/Retired\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 559,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(race_df, \"raceResults\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 560,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "---------------- QUALIFYING ---------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if qualifying_df is not None:\n",
        "    qualifying_df = loc_existing_columns(\n",
        "        qualifying_df,\n",
        "        [\n",
        "            \"eventId\",\n",
        "            \"driverId\",\n",
        "            \"Pos\",\n",
        "            \"Time\",\n",
        "            \"qualy1Time\",\n",
        "            \"qualy1Pos\",\n",
        "            \"qualy2Time\",\n",
        "            \"qualy2Pos\",\n",
        "            \"Q1\",\n",
        "            \"Q2\",\n",
        "            \"Q3\",\n",
        "            \"Laps\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Convert the time text to milliseconds\n",
        "    for col in [\"Time\", \"Q1\", \"Q2\", \"Q3\"]:\n",
        "        qualifying_df[col] = qualifying_df[col].apply(\n",
        "            lambda x: convert_to_milliseconds(x)\n",
        "        )\n",
        "\n",
        "    qualifying_df.rename(\n",
        "        columns={\"Laps\": \"laps\", \"Time\": \"time\", \"Pos\": \"pos\"}, inplace=True\n",
        "    )\n",
        "\n",
        "    for col in [\n",
        "        \"time\",\n",
        "        \"Q1\",\n",
        "        \"Q2\",\n",
        "        \"Q3\",\n",
        "        \"laps\",\n",
        "    ]:\n",
        "        if col in qualifying_df.columns:\n",
        "            qualifying_df[col] = np.floor(\n",
        "                pd.to_numeric(qualifying_df[col], errors=\"ignore\")\n",
        "            ).astype(\"Int64\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 561,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(qualifying_df, \"qualifyingResults\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 562,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "----------------- PIT STOPS ---------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if pit_stop_df is not None:\n",
        "    pit_stop_df = loc_existing_columns(\n",
        "        pit_stop_df, [\"eventId\", \"driverId\", \"Lap\", \"Time\", \"Time of day\", \"annotation\"]\n",
        "    )\n",
        "\n",
        "    # Convert the time text to seconds\n",
        "    pit_stop_df[\"Time\"] = pit_stop_df[\"Time\"].apply(\n",
        "        lambda x: convert_to_milliseconds(x)\n",
        "    )\n",
        "\n",
        "    pit_stop_df.rename(\n",
        "        columns={\"Lap\": \"pitStopLap\", \"Time\": \"time\", \"Time of day\": \"timeOfDay\"},\n",
        "        inplace=True,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 563,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(pit_stop_df, \"pitStops\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 564,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "--------------- FREE PRACTISES ------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "\n",
        "def format_fp_df(df: DataFrame | None):\n",
        "    if df is None:\n",
        "        return df\n",
        "\n",
        "    df = loc_existing_columns(df, [\"eventId\", \"driverId\", \"Pos\", \"Laps\", \"Time\"])\n",
        "\n",
        "    # Convert the time text to seconds\n",
        "    df[\"Time\"] = df[\"Time\"].apply(lambda x: convert_to_milliseconds(x))\n",
        "\n",
        "    df.rename(\n",
        "        columns={\"Laps\": \"laps\", \"Time\": \"time\", \"Pos\": \"pos\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 565,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, df in enumerate([fp1_df, fp2_df, fp3_df, fp4_df]):\n",
        "    download_df(format_fp_df(df), f\"fp{i + 1}_results\")\n",
        "\n",
        "download_df(format_fp_df(wu_df), \"warmingUpResults\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4fe8648bc51823301d9721b2da8cf2e7ea3829482ed2017c7b7190493e72ba7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
