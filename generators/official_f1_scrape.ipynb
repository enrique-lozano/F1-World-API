{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data generator from formula1.com\n",
        "\n",
        "With this script you can push new results posted in the formula 1 official page to the database. This script will be run as soon as possible after each race, so don't worry about reporting this. It is much more important to complete the data that does not come automatically from scraping!\n",
        "\n",
        "The results will be saved in csv files. You have to specify the season and the round of the event that you want to scrape. Results of the race, qualy, practices will be generated.\n",
        "\n",
        "Subsequent manual analysis is required, since this scraped data can carry errors (for example, Nelson Piquet in the 2008/2009 season is assigned the identifier of his father, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from urllib import request\n",
        "import requests\n",
        "import os\n",
        "from unidecode import unidecode\n",
        "import bs4 as bs\n",
        "from typing import Literal\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path of the current data\n",
        "INPUT_PATH = \"./../data/csv/\"\n",
        "\n",
        "# Path to generate the new db files\n",
        "OUTPUT_PATH = \"generated/Data to append to the DB\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_PATH):\n",
        "    os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "API_PATH = \"http://localhost:3200/api\"\n",
        "DB_PATH = \"./../data/db/test.db\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Race to get -> Season + Round\n",
        "SEASON = 2020\n",
        "ROUND = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "def makeSQLQuery(query: str):\n",
        "    sqliteConnection = sqlite3.connect(DB_PATH)\n",
        "    cursor = sqliteConnection.cursor()\n",
        "    print(\"Connected to SQLite\")\n",
        "\n",
        "    cursor.execute(query)\n",
        "    return cursor.fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_df(df: DataFrame | None, name: str):\n",
        "    if df is not None:\n",
        "        df.to_csv(f\"{OUTPUT_PATH}/{name}.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loc_existing_columns(df: DataFrame, columns: list[str]):\n",
        "    \"\"\"Receives a dataframe an a list of columns, and returns the dataframe with the\n",
        "    columns of the list and the columns that are not present filled by and empty string\n",
        "    \"\"\"\n",
        "\n",
        "    invalid_cols = [column for column in columns if column not in df.columns]\n",
        "\n",
        "    for col in invalid_cols:\n",
        "        df[col] = \"\"\n",
        "\n",
        "    valid_cols = [column for column in columns if column in df.columns]\n",
        "\n",
        "    return df.loc[:, valid_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_to_milliseconds(text: str):\n",
        "    \"\"\"Receives a string in the format `HH:mm:ss.SSS` and return the converted milliseconds\"\"\"\n",
        "\n",
        "    if not isinstance(text, str) and not np.isnan(float(text)):\n",
        "        return round(float(text) * 1000)\n",
        "\n",
        "    try:\n",
        "        splitted = list(map(float, text.split(\":\")))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "    result = splitted[-1]\n",
        "    if len(splitted) >= 2:\n",
        "        result += splitted[-2] * 60\n",
        "    if len(splitted) >= 3:\n",
        "        result += splitted[-3] * 3600\n",
        "\n",
        "    return round(result * 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import isnan\n",
        "\n",
        "entrants_in_db = pd.read_csv(INPUT_PATH + \"sessionEntrants.csv\")\n",
        "\n",
        "def find_entrant_id(driver_name: str, car_name: str = \"\"):\n",
        "    driver_name = unidecode(driver_name).replace(\"-\", \" \")\n",
        "\n",
        "    drivers_api_path = f\"{API_PATH}/drivers?name={driver_name.replace(\" \", \"%20\")}&birthBefore={SEASON - 10}-01-01&birthAfter={SEASON - 70}-01-01&include=id\"\n",
        "\n",
        "    driver_res = json.loads(request.urlopen(drivers_api_path).read())\n",
        "    if(driver_res[\"totalElements\"] == 0):\n",
        "        driver_res:dict = json.loads(request.urlopen(\n",
        "            drivers_api_path.replace(driver_name.replace(\" \", \"%20\"), \n",
        "                                     driver_name.split(\" \")[-1])).\n",
        "                                     read())\n",
        "        \n",
        "    results = list(driver_res[\"data\"])\n",
        "\n",
        "    to_return = []\n",
        "\n",
        "    for driver in results:\n",
        "        possible_entrants = json.loads(\n",
        "            request.urlopen(\n",
        "                f\"{API_PATH}/session-entrants?driverId={driver[\"id\"]}&season={SEASON}&include=id\")\n",
        "                .read())\n",
        "        \n",
        "        for entrant in list(possible_entrants[\"data\"]):\n",
        "            to_return.append(entrant[\"id\"])\n",
        "\n",
        "    if(len(results) > 0):\n",
        "        return \"???\".join(to_return)\n",
        "    \n",
        "    return \"???\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_race_urls(season: int):\n",
        "    year = str(season)\n",
        "    race_urls: list[str] = []\n",
        "    source = request.urlopen(\n",
        "        f\"https://www.formula1.com/en/results.html/{year}/races.html\"\n",
        "    ).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    for url in soup.find_all(\"a\"):\n",
        "        if (\n",
        "            year in str(url.get(\"href\"))\n",
        "            and \"race-result\" in str(url.get(\"href\"))\n",
        "            and url.get(\"href\") not in race_urls\n",
        "        ):\n",
        "            race_urls.append(url.get(\"href\"))\n",
        "\n",
        "    return race_urls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_race_data(\n",
        "    race_url: str,\n",
        "    data_to_get: Literal[\n",
        "        \"pit_stops\", \"Q\", \"fp1\", \"fp2\", \"fp3\", \"fp4\", \"wu\", \"R\"\n",
        "    ],\n",
        "    season: int,\n",
        "    round: int,\n",
        "):\n",
        "    last_path_slot: str\n",
        "\n",
        "    if data_to_get == \"pit_stops\":\n",
        "        last_path_slot = \"/pit-stop-summary.html\"\n",
        "    elif data_to_get == \"Q\":\n",
        "        last_path_slot = \"/qualifying-0.html\"\n",
        "    elif data_to_get == \"fp1\":\n",
        "        last_path_slot = \"/practice-1.html\"\n",
        "    elif data_to_get == \"fp2\":\n",
        "        last_path_slot = \"/practice-2.html\"\n",
        "    elif data_to_get == \"fp3\":\n",
        "        last_path_slot = \"/practice-3.html\"\n",
        "    elif data_to_get == \"fp4\":\n",
        "        last_path_slot = \"/practice-4.html\"\n",
        "    elif data_to_get == \"wu\":\n",
        "        last_path_slot = \"/practice-0.html\"\n",
        "    elif data_to_get == \"R\":\n",
        "        last_path_slot = \"/race-result.html\"\n",
        "\n",
        "    source = request.urlopen(\n",
        "        \"https://www.formula1.com/\"\n",
        "        + \"/\".join(race_url.split(\"/\")[:-1])\n",
        "        + last_path_slot\n",
        "    ).read()\n",
        "\n",
        "    soup = bs.BeautifulSoup(source, \"lxml\")\n",
        "\n",
        "    SIDENAV_LIST = soup.find(\"ul\", {\"class\": \"resultsarchive-side-nav\"})\n",
        "\n",
        "    if not SIDENAV_LIST:\n",
        "        return None\n",
        "\n",
        "    if data_to_get == \"pit_stops\" and not \"Pit stop summary\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "\n",
        "    if data_to_get == \"wu\" and not \"Warm Up\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "\n",
        "    if data_to_get == \"R\" and not \"Race result\" in SIDENAV_LIST.text:\n",
        "        return None\n",
        "\n",
        "    for i in range(1, 5):\n",
        "        if data_to_get == f\"fp{i}\" and not f\"Practice {i}\" in SIDENAV_LIST.text:\n",
        "            return None\n",
        "\n",
        "    table = soup.find_all(\"table\")[0]\n",
        "    df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
        "\n",
        "    # Get driver ID\n",
        "    df[\"Driver\"] = df[\"Driver\"].apply(lambda x: \" \".join(x.split(\" \")[:-1]))\n",
        "    df[\"driverId\"] = df[\"Driver\"].map(find_entrant_id)\n",
        "\n",
        "    # Remove unnamed columns\n",
        "    df = df.loc[:, ~df.columns.str.startswith(\"Unnamed: \")]\n",
        "\n",
        "    df[\"season\"] = season\n",
        "    df[\"round\"] = round\n",
        "\n",
        "    df[\"eventId\"] = f\"{season}-{round}-{\"R\" if data_to_get == \"pit_stops\" else data_to_get.upper()}\"\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kikel\\AppData\\Local\\Temp\\ipykernel_10160\\990364925.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
            "C:\\Users\\kikel\\AppData\\Local\\Temp\\ipykernel_10160\\990364925.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
            "C:\\Users\\kikel\\AppData\\Local\\Temp\\ipykernel_10160\\990364925.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
            "C:\\Users\\kikel\\AppData\\Local\\Temp\\ipykernel_10160\\990364925.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n",
            "C:\\Users\\kikel\\AppData\\Local\\Temp\\ipykernel_10160\\990364925.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table), flavor=\"bs4\", header=[0])[0]\n"
          ]
        }
      ],
      "source": [
        "races_url = get_race_urls(SEASON)\n",
        "race = races_url[ROUND - 1]\n",
        "\n",
        "# Comment any of the following blocks to speed-up the proccess:\n",
        "qualifying_df = get_race_data(race, \"Q\", SEASON, ROUND)\n",
        "pit_stop_df = get_race_data(race, \"pit_stops\", SEASON, ROUND)\n",
        "fp1_df = get_race_data(race, \"fp1\", SEASON, ROUND)\n",
        "fp2_df = get_race_data(race, \"fp2\", SEASON, ROUND)\n",
        "fp3_df = get_race_data(race, \"fp3\", SEASON, ROUND)\n",
        "fp4_df = get_race_data(race, \"fp4\", SEASON, ROUND)\n",
        "wu_df = get_race_data(race, \"wu\", SEASON, ROUND)\n",
        "race_df = get_race_data(race, \"R\", SEASON, ROUND)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check that all drivers has been found in our DB\n",
        "for df in [qualifying_df, pit_stop_df, fp1_df, fp2_df, fp3_df]:\n",
        "    if df is not None:\n",
        "        DRIVERS_WITHOUT_ID = df[df[\"driverId\"] == \"\"]\n",
        "        if len(DRIVERS_WITHOUT_ID) > 0:\n",
        "            raise Exception(\n",
        "                \"Can not find any id for this drivers: \",\n",
        "                DRIVERS_WITHOUT_ID[\"Driver\"].unique(),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "--------------- RACE RESULTS --------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if race_df is not None:\n",
        "    race_df[\"positionOrder\"] = race_df.index + 1\n",
        "    race_df[\"pointsCountForWDC\"] = 1\n",
        "    race_df[\"pointsGained\"] = race_df[\"PTS\"]\n",
        "\n",
        "    race_df = loc_existing_columns(\n",
        "        race_df,\n",
        "        [\n",
        "            \"eventId\",\n",
        "            \"driverId\",\n",
        "            \"positionOrder\",\n",
        "            \"Pos\",\n",
        "            \"time\",\n",
        "            \"gridPosition\",\n",
        "            \"gridPenalty\",\n",
        "            \"Time/Retired\",\n",
        "            \"Laps\",\n",
        "            \"PTS\",\n",
        "            \"pointsCountForWDC\",\n",
        "            \"pointsGained\",\n",
        "            \"gap\",\n",
        "            \"timePenalty\",\n",
        "            \"reasonRetired\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    race_df.rename(\n",
        "        columns={\"Laps\": \"laps\", \"PTS\": \"points\", \"Pos\": \"positionText\"}, inplace=True\n",
        "    )\n",
        "\n",
        "    race_df[\"gridPosition\"] = \"COMPLETE_ME\"\n",
        "    race_df[\"gridPenalty\"] = \"COMPLETE_ME\"\n",
        "\n",
        "    race_df[\"gap\"] = race_df.apply(\n",
        "        lambda x: x[\"Time/Retired\"]\n",
        "        if x[\"Time/Retired\"] != \"DNF\" and x[\"positionOrder\"] != 1\n",
        "        else \"\",\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    race_df.at[0, \"time\"] = convert_to_milliseconds(race_df.at[0, \"Time/Retired\"])\n",
        "\n",
        "    race_df[\"time\"] = race_df.apply(\n",
        "        lambda x: race_df.at[0, \"time\"]\n",
        "        + convert_to_milliseconds(\n",
        "            str(x[\"Time/Retired\"]).replace(\"+\", \"\").replace(\"s\", \"\")\n",
        "        )\n",
        "        if \"lap\" not in x[\"Time/Retired\"]\n",
        "        and x[\"positionOrder\"] != 1\n",
        "        and convert_to_milliseconds(\n",
        "            str(x[\"Time/Retired\"]).replace(\"+\", \"\").replace(\"s\", \"\")\n",
        "        )\n",
        "        is not None\n",
        "        else \"\",\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    race_df.at[0, \"time\"] = convert_to_milliseconds(race_df.at[0, \"Time/Retired\"])\n",
        "\n",
        "    race_df[\"positionText\"] = race_df.apply(\n",
        "        lambda x: \"DNF\" if x[\"positionText\"] == \"NC\" else x[\"positionText\"], axis=1\n",
        "    )\n",
        "\n",
        "    race_df[\"reasonRetired\"] = race_df.apply(\n",
        "        lambda x: \"COMPLETE_ME\" if x[\"positionText\"] == \"DNF\" else \"\", axis=1\n",
        "    )\n",
        "\n",
        "    race_df.drop(columns=[\"Time/Retired\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(race_df, \"raceResults\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "---------------- QUALIFYING ---------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if qualifying_df is not None:\n",
        "    qualifying_df[\"positionOrder\"] = qualifying_df.index + 1\n",
        "\n",
        "    qualifying_df = loc_existing_columns(\n",
        "        qualifying_df,\n",
        "        [\n",
        "            \"eventId\",\n",
        "            \"driverId\",\n",
        "            \"positionOrder\",\n",
        "            \"Pos\",\n",
        "            \"Time\",\n",
        "            \"Laps\",\n",
        "            \"Q1\",\n",
        "            \"Q2\",\n",
        "            \"Q3\",\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Convert the time text to milliseconds\n",
        "    for col in [\"Time\", \"Q1\", \"Q2\", \"Q3\"]:\n",
        "        qualifying_df[col] = qualifying_df[col].apply(\n",
        "            lambda x: convert_to_milliseconds(x)\n",
        "        )\n",
        "\n",
        "    qualifying_df.rename(\n",
        "        columns={\n",
        "            \"Laps\": \"laps\",\n",
        "            \"Time\": \"time\",\n",
        "            \"Pos\": \"positionText\",\n",
        "            \"Q1\": \"q1Time\",\n",
        "            \"Q2\": \"q2Time\",\n",
        "            \"Q3\": \"q3Time\",\n",
        "        },\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    for col in [\n",
        "        \"time\",\n",
        "        \"q1Time\",\n",
        "        \"q2Time\",\n",
        "        \"q3Time\",\n",
        "        \"laps\",\n",
        "    ]:\n",
        "        if col in qualifying_df.columns:\n",
        "            qualifying_df[col] = np.floor(\n",
        "                pd.to_numeric(qualifying_df[col], errors=\"ignore\")\n",
        "            ).astype(\"Int64\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(qualifying_df, \"qualifyingResults\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "----------------- PIT STOPS ---------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "if pit_stop_df is not None:\n",
        "    pit_stop_df = loc_existing_columns(\n",
        "        pit_stop_df, [\"eventId\", \"driverId\", \"Lap\", \"Time\", \"Time of day\", \"annotation\"]\n",
        "    )\n",
        "\n",
        "    # Convert the time text to seconds\n",
        "    pit_stop_df[\"Time\"] = pit_stop_df[\"Time\"].apply(\n",
        "        lambda x: convert_to_milliseconds(x)\n",
        "    )\n",
        "\n",
        "    pit_stop_df.rename(\n",
        "        columns={\"Lap\": \"pitStopLap\", \"Time\": \"time\", \"Time of day\": \"timeOfDay\"},\n",
        "        inplace=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_df(pit_stop_df, \"pitStops\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\" ---------------------------------------------\n",
        "--------------- FREE PRACTISES ------------------\n",
        "--------------------------------------------- \"\"\"\n",
        "\n",
        "\n",
        "def format_fp_df(df: DataFrame | None):\n",
        "    if df is None:\n",
        "        return df\n",
        "\n",
        "    df[\"positionOrder\"] = df.index + 1\n",
        "\n",
        "    df = loc_existing_columns(\n",
        "        df, [\"eventId\", \"driverId\", \"positionOrder\", \"Pos\", \"Laps\", \"Time\"]\n",
        "    )\n",
        "\n",
        "    # Convert the time text to seconds\n",
        "    df[\"Time\"] = df[\"Time\"].apply(lambda x: convert_to_milliseconds(x))\n",
        "\n",
        "    df.rename(\n",
        "        columns={\"Laps\": \"laps\", \"Time\": \"time\", \"Pos\": \"pos\"},\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, df in enumerate([fp1_df, fp2_df, fp3_df, fp4_df]):\n",
        "    download_df(format_fp_df(df), f\"fp{i + 1}_results\")\n",
        "\n",
        "download_df(format_fp_df(wu_df), \"warmingUpResults\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4fe8648bc51823301d9721b2da8cf2e7ea3829482ed2017c7b7190493e72ba7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
