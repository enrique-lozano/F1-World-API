{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "File used to generate the first annotations on the pit stops. The rest of the annotations has been enter manually\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASETS_PATH = \"./../data/\"\n",
        "\n",
        "pit_stops = pd.read_json(DATASETS_PATH + \"pitStops.json\")\n",
        "pit_stops.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops[\"year\"] = pit_stops[\"eventId\"].apply(lambda x: str(x).split(\"-\")[0]).astype(\"Int64\")\n",
        "pit_stops[\"pitStopIndex\"] = pit_stops.index\n",
        "\n",
        "pit_stops.groupby([\"year\"])[\"time\"].describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we realize that some pit stops are too large to be real. More than 1000 secs (more than 15mins). So we continue to see what happen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops[(pit_stops[\"time\"] > 1000000) & (pit_stops[\"year\"] == 2016)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that red flags are taken into account and count as a Pit Stop. We should fix that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops[(pit_stops[\"driverId\"] == \"daniel-ricciardo\") & (pit_stops[\"eventId\"] == \"2016-1\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that also the \"red flags pit stops\" count for the total number of pits for the driver. By the moment, we just want to remove the rows of this pits, because we want the median time of the pit. We could deal with the pitStopNumber later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "red_flags = pd.read_json(DATASETS_PATH + \"redFlags.json\")\n",
        "\n",
        "red_flags.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.rename(columns={\"lap\": \"pitStopLap\"}, inplace=True)\n",
        "\n",
        "merged = pd.merge(\n",
        "    red_flags, pit_stops, on=[\"eventId\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the data of the laps with pit stops refearing as a red flag\n",
        "merged = merged[\n",
        "    (~merged[\"pitStopLap\"].isna())\n",
        "    & (\n",
        "        (merged[\"pitStopLap\"] == merged[\"lap\"])\n",
        "        | ((merged[\"pitStopLap\"] == merged[\"lap\"] - 1) & (merged[\"time\"] > 200))\n",
        "        | ((merged[\"pitStopLap\"] == merged[\"lap\"] - 2) & (merged[\"time\"] > 300))\n",
        "    )\n",
        "]\n",
        "\n",
        "merged.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add annotations to the pit stops in special cases like this:\n",
        "pit_stops[\"annotation\"] = \"\"\n",
        "pit_stops.loc[merged[\"pitStopIndex\"], \"annotation\"] = \"Red flag\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check that annotations has been added correctly\n",
        "pit_stops[pit_stops[\"annotation\"] == \"Red flag\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops[(pit_stops[\"time\"] > 200000) & (pit_stops[\"annotation\"] == \"\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pit stops that took less than 13.75seg\n",
        "pit_stops[pit_stops[\"time\"] < 13750].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now stop worrying about excessively long stops. There are only a couple of them that are isolated cases and we can manually delete them later. However, we see that there are very short pits. This is in many cases due to drive-throughs, which we must identify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preparing for dropping unreal low-time pits. First, calculate the standard deviation per race, and then, get the values with a high variation from that value\n",
        "std_per_race = (\n",
        "    pit_stops[pit_stops[\"annotation\"] == \"\"]\n",
        "    .groupby([\"eventId\", \"year\"])[\"time\"]\n",
        "    .aggregate([\"std\", \"median\"])\n",
        ")\n",
        "std_per_race = std_per_race.rename(\n",
        "    columns={\"std\": \"pitStopSegsRaceVariation\", \"median\": \"pitStopSegsRaceMedian\"}\n",
        ")\n",
        "std_per_race\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "std_per_race = pd.merge(pit_stops[pit_stops[\"annotation\"] == \"\"], std_per_race, on=\"eventId\")\n",
        "std_per_race.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Values with a non-normal low pit-stop\n",
        "std_per_race[\"deviation\"] = (\n",
        "    std_per_race[\"time\"] - std_per_race[\"pitStopSegsRaceMedian\"]\n",
        ") / std_per_race[\"pitStopSegsRaceVariation\"]\n",
        "\n",
        "low_pit_stops = std_per_race[std_per_race[\"deviation\"] < -1.5].sort_values(by=\"eventId\")\n",
        "\n",
        "low_pit_stops.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops[pit_stops[\"eventId\"] == \"2022-2\"].sort_values(\"time\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "low_pit_stops[low_pit_stops[\"time\"] < 13250].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now we can get which of this values are because a drive-through\n",
        "\n",
        "# First, create a df containing all penalties that have the same driver and race that a non-usual low-time pit stop \n",
        "\n",
        "penalties = pd.read_json(DATASETS_PATH + \"penalties.json\")\n",
        "low_pits_with_penalties = pd.merge(low_pit_stops, penalties, on=[\"eventId\", \"driverId\"])\n",
        "\n",
        "print(f\"{len(low_pits_with_penalties)} rows with rare low-pit time and a penalty in the same race:\\n\")\n",
        "low_pits_with_penalties.sort_values(\"time\").head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Secondly, we filter that df with only the penalties that are drive-through\n",
        "low_pits_with_penalties = low_pits_with_penalties[\n",
        "    low_pits_with_penalties[\"Outcome\"].apply(\n",
        "        lambda x: \"Drive-through penalty\" in str(x).split(\",\")\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"{len(low_pits_with_penalties)} rows with drive-through:\\n\")\n",
        "low_pits_with_penalties.sort_values(\"time\").head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.loc[low_pits_with_penalties[\"pitStopIndex\"].astype(\"int\").to_list(), \"annotation\"] = \"Drive-through\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove pits where cars follow the SC\n",
        "index_to_note = (\n",
        "    pit_stops[\n",
        "        ((pit_stops[\"eventId\"] == \"2017-8\") & (pit_stops[\"pitStopLap\"] == 17))\n",
        "        | ((pit_stops[\"eventId\"] == \"2021-6\") & (pit_stops[\"pitStopLap\"] == 47))\n",
        "    ][\"pitStopIndex\"]\n",
        "    .astype(\"int\")\n",
        "    .to_list()\n",
        ")\n",
        "\n",
        "pit_stops.loc[index_to_note, \"annotation\"] = \"All cars follow the SC through the pit lane\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.groupby(\"annotation\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Same way as before, but with the long pits\n",
        "long_pit_stops = std_per_race[(std_per_race[\"deviation\"] > 1.5) & (std_per_race[\"time\"] < 45000)].sort_values(by=\"eventId\")\n",
        "\n",
        "long_pits_with_penalties = pd.merge(\n",
        "    long_pit_stops, penalties, on=[\"eventId\", \"driverId\"]\n",
        ")\n",
        "\n",
        "# Secondly, we filter that df with only the penalties that are drive-through\n",
        "long_pits_with_penalties = long_pits_with_penalties[\n",
        "    long_pits_with_penalties[\"Outcome\"].apply(\n",
        "        lambda x: \"Ten-second stop-go penalty\" in str(x).split(\",\")\n",
        "        or \"Ten-second time penalty\" in str(x).split(\",\")\n",
        "        or \"Five-second time penalty\" in str(x).split(\",\")\n",
        "    )\n",
        "]\n",
        "\n",
        "long_pits_with_penalties.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.loc[\n",
        "    long_pits_with_penalties[\"pitStopIndex\"].astype(\"int\").to_list(), \"annotation\"\n",
        "] = (long_pits_with_penalties[\"Outcome\"].apply(lambda x: str(x).split(\",\")[0])).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------- FINAL MODIFICATIONS ------------------\n",
        "\n",
        "pit_stops.drop(columns=[\"year\", \"pitStopIndex\"], inplace=True)\n",
        "pit_stops.rename(columns={\"pitStopLap\": \"lap\"}, inplace=True)\n",
        "\n",
        "pit_stops.groupby(\"annotation\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pit_stops.to_json(\"./pitStops.json\", \"records\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4fe8648bc51823301d9721b2da8cf2e7ea3829482ed2017c7b7190493e72ba7a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
